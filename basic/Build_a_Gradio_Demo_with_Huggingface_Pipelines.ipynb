{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fzantalis/gradio_demos/blob/main/basic/Build_a_Gradio_Demo_with_Huggingface_Pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR_eGaUvCXln"
      },
      "source": [
        "# Building your first demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe4lE_tjCXlt"
      },
      "source": [
        "Αρχικά εγκαθιστούμε τις βιβλιοθήκες που χρειαζόμαστε.\n",
        "Θα χρησιμοποιήσουμε την βιβλιοθήκη transformers του Huggingface και την gradio  για να φτιάξουμε το γραφικό μας περιβάλλον. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9RQK9PiCXlu"
      },
      "outputs": [],
      "source": [
        "!pip install  transformers[sentencepiece]\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Η πιο απλή εφαρμογή\n",
        "Αυτό είναι το πρώτο και πιο απλό παράδειγμα που μπορούμε να φτιάξουμε.\n",
        "Εδώ θα εξοικειωθούμε με την κλάση Interface.\n",
        "Αυτή η κλάση είναι υπεύθυνη για την κατασκευή του γραφικού μας περιβάλλοντος στο Gradio demo μας.\n",
        "\n",
        "Όπως βλέπουμε η κλάσση Interface παίρνει 3 βασικά ορίσματα. \n",
        "\n",
        "```\n",
        " gr.Interface(fn=..., inputs=\"...\", outputs=\"...\")\n",
        "```\n",
        "\n",
        "* Στο **fn** βάζουμε την συνάρτηση που θα τρέχει κατα την εκτέλεση του.\n",
        "παραδείγματος.\n",
        "* Στο **inputs** ορίζουμε τον τύπο των δεδομένων που θέλουμε να μπορεί να εισάγει ο χρήστης. Στην περίπτωση μας θέλουμε ένα πεδίο κειμένου οπότε βάζουμε την λέξη **\"text\"**. Όμως η Interface μας δίνει πολλές επιλογές και θα μπορούσαμε να δώσουμε στον χρήστη την δυνατότητα να εισάγει εικόνες, ήχους, βίντεο από την κάμερα κτλ. με λέξεις κλειδιά όπως **\"image\", \"mic\"** κ.α.\n",
        "* Τέλος το **outputs** καθορίζει τον τύπο των δεδομένων που θα μας επιστρέψει το παράδειγμα. Όπως και στο inputs έχουμε αρκετές επιλογές αλλά στην περίπτωση μας επιλέγουμε το **\"text\"** για να τυπώσουμε κείμενο."
      ],
      "metadata": {
        "id": "8fXMbUm-09zD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_FeMZu8CXlw"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "def hello(name):\n",
        "    return \"Hello \" + name\n",
        "\n",
        "\n",
        "demo = gr.Interface(fn=hello, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Αυτόματη συμπλήρωση κειμένου με την χρήση Pipelines\n",
        "Η συνάρτηση pipeline είναι μέρος της βιβλιοθήκης transformers της huggingface.\n",
        "Με την pipeline μπορούμε πολύ εύκολα να καλέσουμε κάποιο μοντέλο μέσα στην εφαρμογή μας.\n",
        "Στην περίπτωση μας θέλουμε να χρησιμοποιήσουμε την pipeline για αυτόματη παραγωγή κειμένου. Συνεπώς θα την καλέσουμε με το όρισμα \"text-generation\" \n",
        "```\n",
        "pipeline(\"text-generation\")\n",
        "```\n",
        "Η συνάρτηση pipeline αυτοματοποιεί για εμάς 3 βήματα.\n",
        "1. Το κείμενο που θα εισάγουμε επεξεργάζεται ώστε να το \"καταλαβαίνει\" το μοντέλο μας\n",
        "2. Το επεξεργαζμένο κείμενο τροφοδοτείται στο μοντέλο\n",
        "3. Η έξοδος του μοντέλου επιστρέφει σε εμάς\n",
        "\n",
        "Αν δεν ορίσουμε στην Pipeline ποιο μοντέλο θέλουμε να χρησιμοποιήσει, θα επιλέξει αυτόματα ένα κατάλληλο μοντέλο για την διεργασία που ζητήσαμε. πχ text-generation.\n",
        "\n",
        "Αν θέλουμε να ορίσουμε ποιο μοντέλο να χρησιμοποιήσει, μπορούμε να το κάνουμε με το όρισμα model.\n",
        "```\n",
        "pipeline(\"text-generation\" , model=\"gpt2\")\n",
        "```\n",
        "Πέρα από το \"text-generation\", η pipeline μας επιτρέπει να διαλέξουμε τις παρακάτω διεργασίες:\n",
        "* feature-extraction (get the vector representation of a text)\n",
        "* fill-mask\n",
        "* ner (named entity recognition)\n",
        "* question-answering\n",
        "* sentiment-analysis\n",
        "* summarization\n",
        "* translation\n",
        "* zero-shot-classification "
      ],
      "metadata": {
        "id": "_eBelwhGsZtB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhNiYYb7CXlz"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "title = \"Συμπλήρωση κειμένου με το μοντέλο GPT2\"\n",
        "description = \"Ένα απλό gradio demo για να δούμε πως φτιάχνουμε εύκολα A.I. εφαρμογές με την χρήση των Pipelines\"\n",
        "examples = [\n",
        "    [\"Mike was the famous space mouse\"],\n",
        "    [\"The Earth's perimeter is\"],\n",
        "    [\"You will never believe what happened yesterday on my way back home.\"],\n",
        "]\n",
        "\n",
        "model = pipeline(\"text-generation\" , model=\"gpt2\")\n",
        "\n",
        "\n",
        "def predict(prompt):\n",
        "    completion = model(prompt)[0][\"generated_text\"]\n",
        "    return completion\n",
        "\n",
        "gr.Interface(\n",
        "    fn=predict, \n",
        "    inputs=\"text\", \n",
        "    outputs=\"text\",\n",
        "    title=title,\n",
        "    description=description,\n",
        "    examples=examples,\n",
        "    enable_queue=True,\n",
        "    ).launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}